# CYNIC Ecosystem Roadmap - Complete Implementation Guide

> **Document crÃ©Ã©**: 2026-01-15
> **Objectif**: Guide complet pour implÃ©menter la conscience collective CYNIC
> **Philosophie**: "Ï† qui se mÃ©fie de Ï†" - Don't Trust, Verify

---

## ğŸ“Š Ã‰TAT ACTUEL DE L'INFRASTRUCTURE

### Services Render (Production)

| Service | Type | Status | URL |
|---------|------|--------|-----|
| **asdf-brain** | Web | âœ… Active | https://asdf-brain.onrender.com |
| **gasdf** | Web | âœ… Active | https://gasdf-43r8.onrender.com |
| **gasdf-metrics** | Web | âœ… Active | https://gasdf-metrics.onrender.com |
| **holdex-api** | Web | â¸ï¸ Suspended | https://holdex-api.onrender.com |
| **holdex-calculator** | Worker | â¸ï¸ Suspended | - |

### Bases de DonnÃ©es (Production)

| Database | Type | Plan | Status | Usage |
|----------|------|------|--------|-------|
| **cynic-db** | PostgreSQL 16 | basic_256mb (15GB) | âœ… Available | CYNIC persistence |
| **holdex-db** | PostgreSQL 16 | basic_256mb (15GB) | âœ… Available | K-Score, E-Score |
| **gasdf-db** | PostgreSQL 16 | free | âš ï¸ Expires 2026-02-01 | GASdf burns |

### Redis (Cache)

| Instance | Plan | Status | Usage |
|----------|------|--------|-------|
| **holdex-redis** | starter | âœ… Available | Token cache, rate limits |
| **gasdf-redis** | free | âœ… Available | Quotes, sessions |

---

## ğŸ—ï¸ ARCHITECTURE CIBLE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           $ASDFASDFA ECOSYSTEM                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                    CYNIC - CONSCIENCE COLLECTIVE                        â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚
â”‚  â”‚  â”‚ MCP Server  â”‚  â”‚  PostgreSQL â”‚  â”‚    Redis    â”‚  â”‚  Sub-Agents â”‚   â”‚â”‚
â”‚  â”‚  â”‚ (stdio)     â”‚  â”‚  (cynic-db) â”‚  â”‚  (cache)    â”‚  â”‚  (isolÃ©s)   â”‚   â”‚â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚   â”‚â”‚
â”‚  â”‚  â”‚ â€¢ judge     â”‚  â”‚ â€¢ judgments â”‚  â”‚ â€¢ sessions  â”‚  â”‚ â€¢ observer  â”‚   â”‚â”‚
â”‚  â”‚  â”‚ â€¢ digest    â”‚  â”‚ â€¢ patterns  â”‚  â”‚ â€¢ lib cache â”‚  â”‚ â€¢ digester  â”‚   â”‚â”‚
â”‚  â”‚  â”‚ â€¢ search    â”‚  â”‚ â€¢ users     â”‚  â”‚ â€¢ hot data  â”‚  â”‚ â€¢ guardian  â”‚   â”‚â”‚
â”‚  â”‚  â”‚ â€¢ patterns  â”‚  â”‚ â€¢ poj_chain â”‚  â”‚             â”‚  â”‚ â€¢ mentor    â”‚   â”‚â”‚
â”‚  â”‚  â”‚ â€¢ feedback  â”‚  â”‚ â€¢ knowledge â”‚  â”‚             â”‚  â”‚ â€¢ experts   â”‚   â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚
â”‚  â”‚         â”‚                â”‚                â”‚                â”‚          â”‚â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚â”‚
â”‚  â”‚                                   â”‚                                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                      â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    APPLICATIONS (Consumers)                           â”‚ â”‚
â”‚  â”‚                                   â”‚                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   HolDex    â”‚  â”‚    GASdf    â”‚  â”‚ asdf-brain  â”‚  â”‚   Future    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ K-Score   â”‚  â”‚ â€¢ Gasless   â”‚  â”‚ â€¢ Context   â”‚  â”‚ â€¢ Market-   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ E-Score   â”‚  â”‚ â€¢ Burns     â”‚  â”‚ â€¢ Sessions  â”‚  â”‚   place     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Oracle    â”‚  â”‚ â€¢ Discounts â”‚  â”‚ â€¢ Patterns  â”‚  â”‚ â€¢ SDK       â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—„ï¸ SCHÃ‰MA BASE DE DONNÃ‰ES (cynic-db)

### Tables Principales

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- USERS: IdentitÃ©s et E-Score des utilisateurs
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE users (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    external_id     VARCHAR(255) UNIQUE NOT NULL,  -- GitHub ID, wallet, etc.
    display_name    VARCHAR(255),
    e_score         DECIMAL(10,4) DEFAULT 0,
    burn_total      BIGINT DEFAULT 0,

    -- Operator identity (from CYNIC)
    public_key      VARCHAR(128),

    -- Stats
    total_judgments BIGINT DEFAULT 0,
    avg_q_score     DECIMAL(5,2) DEFAULT 50,

    created_at      TIMESTAMPTZ DEFAULT NOW(),
    updated_at      TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_users_external_id ON users(external_id);
CREATE INDEX idx_users_e_score ON users(e_score DESC);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- JUDGMENTS: Tous les jugements (append-only log)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE judgments (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    judgment_id     VARCHAR(32) UNIQUE NOT NULL,  -- jdg_xxxxx
    user_id         UUID REFERENCES users(id),

    -- What was judged
    item_type       VARCHAR(50) NOT NULL,  -- 'code', 'decision', 'pattern', etc.
    item_content    TEXT NOT NULL,
    item_hash       VARCHAR(64) NOT NULL,  -- SHA-256 for dedup

    -- Scores
    q_score         DECIMAL(5,2) NOT NULL,
    global_score    DECIMAL(5,2) NOT NULL,
    confidence      DECIMAL(5,4) NOT NULL,
    verdict         VARCHAR(10) NOT NULL,  -- HOWL, WAG, GROWL, BARK

    -- Axiom breakdown (JSONB for flexibility)
    axiom_scores    JSONB NOT NULL,  -- {PHI: 56.2, VERIFY: 48.6, ...}
    dimension_scores JSONB,          -- All 25 dimensions
    weaknesses      JSONB,           -- {weakestAxiom, recommendation, ...}

    -- Context
    context         JSONB,           -- Source, project, etc.

    -- Chain link (for PoJ)
    prev_hash       VARCHAR(64),
    block_hash      VARCHAR(64),

    created_at      TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_judgments_user ON judgments(user_id);
CREATE INDEX idx_judgments_verdict ON judgments(verdict);
CREATE INDEX idx_judgments_q_score ON judgments(q_score DESC);
CREATE INDEX idx_judgments_created ON judgments(created_at DESC);
CREATE INDEX idx_judgments_item_hash ON judgments(item_hash);

-- Partitioning by month for scalability
-- CREATE TABLE judgments_2026_01 PARTITION OF judgments
--     FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- PATTERNS: Patterns extraits (consensus-approved)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE patterns (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    pattern_id      VARCHAR(32) UNIQUE NOT NULL,  -- pat_xxxxx

    -- Classification
    axiom           VARCHAR(10) NOT NULL,  -- PHI, VERIFY, CULTURE, BURN
    category        VARCHAR(50) NOT NULL,  -- 'technical', 'process', 'architecture'
    project         VARCHAR(50),           -- 'holdex', 'gasdf', 'all'

    -- Content
    title           VARCHAR(255) NOT NULL,
    content         TEXT NOT NULL,
    tags            TEXT[],

    -- Quality
    q_score_avg     DECIMAL(5,2) DEFAULT 50,
    usage_count     BIGINT DEFAULT 0,
    consensus_score DECIMAL(5,4),  -- % of nodes agreeing

    -- Source
    source_judgment_id UUID REFERENCES judgments(id),
    discovered_by   UUID REFERENCES users(id),

    -- State
    status          VARCHAR(20) DEFAULT 'pending',  -- pending, approved, deprecated

    created_at      TIMESTAMPTZ DEFAULT NOW(),
    approved_at     TIMESTAMPTZ
);

CREATE INDEX idx_patterns_axiom ON patterns(axiom);
CREATE INDEX idx_patterns_category ON patterns(category);
CREATE INDEX idx_patterns_project ON patterns(project);
CREATE INDEX idx_patterns_status ON patterns(status);

-- Full-text search
CREATE INDEX idx_patterns_fts ON patterns
    USING GIN (to_tsvector('english', title || ' ' || content));

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- KNOWLEDGE: Knowledge tree entries (Merkle-verified)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE knowledge (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    knowledge_id    VARCHAR(32) UNIQUE NOT NULL,  -- knw_xxxxx

    -- Tree position
    axiom           VARCHAR(10) NOT NULL,
    tree_type       VARCHAR(20) NOT NULL,  -- 'patterns', 'learnings'
    merkle_hash     VARCHAR(64),
    parent_hash     VARCHAR(64),

    -- Content
    content_type    VARCHAR(50) NOT NULL,  -- 'digest', 'learning', 'pattern'
    content         JSONB NOT NULL,

    -- Metadata
    source          VARCHAR(255),
    user_id         UUID REFERENCES users(id),

    created_at      TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_knowledge_axiom ON knowledge(axiom);
CREATE INDEX idx_knowledge_type ON knowledge(content_type);
CREATE INDEX idx_knowledge_merkle ON knowledge(merkle_hash);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- FEEDBACK: Learning from outcomes
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE feedback (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    feedback_id     VARCHAR(32) UNIQUE NOT NULL,  -- fbk_xxxxx

    -- What we're correcting
    judgment_id     UUID REFERENCES judgments(id) NOT NULL,
    user_id         UUID REFERENCES users(id) NOT NULL,

    -- Correction
    outcome         VARCHAR(20) NOT NULL,  -- 'correct', 'incorrect', 'partial'
    actual_score    DECIMAL(5,2),
    reason          TEXT,

    -- Learning
    residual        DECIMAL(5,2),  -- expected - actual
    learning_created BOOLEAN DEFAULT FALSE,

    created_at      TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_feedback_judgment ON feedback(judgment_id);
CREATE INDEX idx_feedback_user ON feedback(user_id);
CREATE INDEX idx_feedback_outcome ON feedback(outcome);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- POJ_BLOCKS: Proof of Judgment blockchain
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE poj_blocks (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Block identity
    block_number    BIGINT UNIQUE NOT NULL,
    block_hash      VARCHAR(64) UNIQUE NOT NULL,
    prev_hash       VARCHAR(64) NOT NULL,

    -- Block type
    block_type      VARCHAR(20) NOT NULL,  -- 'genesis', 'judgment', 'knowledge', 'governance'

    -- Content
    judgments       UUID[],  -- References to judgments in this block
    state_root      VARCHAR(64),  -- Merkle root of knowledge tree

    -- Signing
    operator_id     UUID REFERENCES users(id),
    signature       VARCHAR(128),

    -- Timing (Ï†-based slots)
    slot            BIGINT NOT NULL,
    timestamp       TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_poj_blocks_number ON poj_blocks(block_number);
CREATE INDEX idx_poj_blocks_hash ON poj_blocks(block_hash);
CREATE INDEX idx_poj_blocks_prev ON poj_blocks(prev_hash);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- SESSIONS: Active user sessions
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE sessions (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id      VARCHAR(64) UNIQUE NOT NULL,
    user_id         UUID REFERENCES users(id),

    -- Context
    project         VARCHAR(50),
    started_at      TIMESTAMPTZ DEFAULT NOW(),
    last_active     TIMESTAMPTZ DEFAULT NOW(),
    ended_at        TIMESTAMPTZ,

    -- Stats
    judgments_made  INT DEFAULT 0,
    patterns_found  INT DEFAULT 0,

    -- State (JSONB for flexibility)
    context_state   JSONB,  -- anomalies, mentor state, etc.

    -- Quality metrics
    token_efficiency DECIMAL(5,4) DEFAULT 1.0,
    task_completion DECIMAL(5,4) DEFAULT 1.0,
    context_freshness DECIMAL(5,4) DEFAULT 1.0,
    quality_score   DECIMAL(5,2) GENERATED ALWAYS AS (
        100 * POWER(token_efficiency * task_completion * context_freshness, 0.333)
    ) STORED
);

CREATE INDEX idx_sessions_user ON sessions(user_id);
CREATE INDEX idx_sessions_project ON sessions(project);
CREATE INDEX idx_sessions_active ON sessions(ended_at) WHERE ended_at IS NULL;

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- LIBRARY_CACHE: Cached documentation (Context7)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE library_cache (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Library identity
    library_id      VARCHAR(128) NOT NULL,  -- /org/project
    query           VARCHAR(512) NOT NULL,
    query_hash      VARCHAR(64) NOT NULL,

    -- Cached content
    content         TEXT NOT NULL,
    summary         TEXT,

    -- TTL management
    fetched_at      TIMESTAMPTZ DEFAULT NOW(),
    expires_at      TIMESTAMPTZ NOT NULL,
    hit_count       BIGINT DEFAULT 0,
    last_hit        TIMESTAMPTZ,

    UNIQUE(library_id, query_hash)
);

CREATE INDEX idx_library_cache_lib ON library_cache(library_id);
CREATE INDEX idx_library_cache_expires ON library_cache(expires_at);
CREATE INDEX idx_library_cache_hash ON library_cache(query_hash);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ECOSYSTEM_DOCS: Pre-loaded ecosystem documentation
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE ecosystem_docs (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Document identity
    project         VARCHAR(50) NOT NULL,
    doc_type        VARCHAR(50) NOT NULL,  -- 'claude_md', 'harmony', 'api'
    file_path       VARCHAR(512) NOT NULL,

    -- Content
    content         TEXT NOT NULL,
    digest          TEXT,  -- AI-generated summary

    -- Version tracking
    content_hash    VARCHAR(64) NOT NULL,
    updated_at      TIMESTAMPTZ DEFAULT NOW(),

    UNIQUE(project, doc_type)
);

CREATE INDEX idx_ecosystem_docs_project ON ecosystem_docs(project);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ANOMALIES: Detected anomalies (ephemeral â†’ persistent if significant)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CREATE TABLE anomalies (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Source
    judgment_id     UUID REFERENCES judgments(id),
    user_id         UUID REFERENCES users(id),

    -- Anomaly details
    residual        DECIMAL(5,2) NOT NULL,
    expected_score  DECIMAL(5,2),
    actual_score    DECIMAL(5,2),

    -- Classification
    anomaly_type    VARCHAR(50),  -- 'score_deviation', 'pattern_break', etc.
    severity        VARCHAR(20),  -- 'low', 'medium', 'high'

    -- Resolution
    resolved        BOOLEAN DEFAULT FALSE,
    resolution      TEXT,

    created_at      TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_anomalies_user ON anomalies(user_id);
CREATE INDEX idx_anomalies_residual ON anomalies(residual DESC);
CREATE INDEX idx_anomalies_unresolved ON anomalies(resolved) WHERE NOT resolved;
```

### Redis Structure

```
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SESSION DATA (ephemeral)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cynic:session:{session_id}              â†’ HASH { user_id, project, started_at, ... }
cynic:session:{session_id}:anomalies    â†’ LIST [anomaly_json, ...] (last 100)
cynic:session:{session_id}:judgments    â†’ LIST [judgment_id, ...] (last 100)
cynic:active_sessions                   â†’ SET [session_id, ...]

# TTL: 24 heures aprÃ¨s last_active

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LIBRARY CACHE (Context7 results)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cynic:libcache:{library_id}:{query_hash} â†’ STRING (compressed content)
cynic:libcache:index                     â†’ HASH { query_hash â†’ library_id }

# TTL: Variable selon stabilitÃ© de la lib (3-30 jours)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HOT DATA (frÃ©quemment accÃ©dÃ©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cynic:user:{user_id}                    â†’ HASH { e_score, total_judgments, ... }
cynic:stats:global                      â†’ HASH { total_judgments, avg_score, ... }
cynic:patterns:hot                      â†’ ZSET (pattern_id â†’ usage_count)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RATE LIMITING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cynic:ratelimit:{user_id}:judge         â†’ STRING (count) + TTL 60s
cynic:ratelimit:{user_id}:search        â†’ STRING (count) + TTL 60s

# Limits: judge=100/min, search=200/min, digest=50/min
```

---

## ğŸš€ ROADMAP DÃ‰TAILLÃ‰E

### Phase 1: Persistence Layer (Semaine 1-2)
**Objectif**: CYNIC persiste ses donnÃ©es dans PostgreSQL + Redis

#### 1.1 Schema Migration
```bash
# Fichiers Ã  crÃ©er
CYNIC-new/packages/persistence/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js              # Export principal
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â”œâ”€â”€ client.js         # Pool connection
â”‚   â”‚   â”œâ”€â”€ migrations/       # SQL migrations
â”‚   â”‚   â”‚   â”œâ”€â”€ 001_initial.sql
â”‚   â”‚   â”‚   â””â”€â”€ 002_indexes.sql
â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚       â”œâ”€â”€ judgments.js
â”‚   â”‚       â”œâ”€â”€ patterns.js
â”‚   â”‚       â”œâ”€â”€ users.js
â”‚   â”‚       â”œâ”€â”€ knowledge.js
â”‚   â”‚       â””â”€â”€ sessions.js
â”‚   â””â”€â”€ redis/
â”‚       â”œâ”€â”€ client.js         # Redis connection
â”‚       â”œâ”€â”€ session-store.js  # Session management
â”‚       â””â”€â”€ cache.js          # Library cache
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

#### 1.2 Tasks
- [ ] CrÃ©er `packages/persistence` avec structure
- [ ] ImplÃ©menter PostgreSQL client avec pool
- [ ] CrÃ©er migration SQL initiale
- [ ] ImplÃ©menter `JudgmentRepository` (CRUD + search)
- [ ] ImplÃ©menter `PatternRepository`
- [ ] ImplÃ©menter `UserRepository`
- [ ] ImplÃ©menter `SessionRepository`
- [ ] Connecter Redis pour sessions
- [ ] Tests unitaires pour chaque repository
- [ ] Documentation API

#### 1.3 Connexions
```javascript
// Environment variables needed
CYNIC_DATABASE_URL=postgresql://cynic_db_user:xxx@oregon-postgres.render.com/cynic_db
CYNIC_REDIS_URL=redis://red-xxx.oregon.render.com:6379
```

---

### Phase 2: MCP Server Integration (Semaine 2-3)
**Objectif**: MCP tools utilisent la persistence

#### 2.1 Modifications MCP Server
```bash
# Fichiers Ã  modifier
CYNIC-new/packages/mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.js             # Injecter persistence
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ judge.js          # â†’ Sauvegarder dans PostgreSQL
â”‚       â”œâ”€â”€ digest.js         # â†’ Sauvegarder dans knowledge
â”‚       â”œâ”€â”€ search.js         # â†’ Query PostgreSQL + full-text
â”‚       â”œâ”€â”€ patterns.js       # â†’ Query patterns table
â”‚       â””â”€â”€ feedback.js       # â†’ Sauvegarder + learning loop
```

#### 2.2 Tasks
- [ ] Modifier `MCPServer` constructor pour accepter persistence
- [ ] Modifier `brain_cynic_judge` â†’ save to `judgments` table
- [ ] Modifier `brain_search` â†’ query PostgreSQL with FTS
- [ ] Modifier `brain_patterns` â†’ query patterns table
- [ ] Modifier `brain_cynic_digest` â†’ save to `knowledge` table
- [ ] Modifier `brain_cynic_feedback` â†’ save + create learning
- [ ] Ajouter `brain_sync` tool pour forcer sync
- [ ] Tests d'intÃ©gration avec vraie DB

---

### Phase 3: Multi-User Sessions (Semaine 3-4)
**Objectif**: Isolation par utilisateur

#### 3.1 Session Manager
```javascript
// Nouveau fichier: packages/mcp/src/session-manager.js

class SessionManager {
  constructor(persistence) {
    this.persistence = persistence;
    this.activeSessions = new Map();
  }

  async getOrCreateSession(userId, project) {
    // 1. Check Redis for active session
    // 2. If not, create new session
    // 3. Load user context from PostgreSQL
    // 4. Return isolated session state
  }

  async endSession(sessionId) {
    // 1. Persist session stats
    // 2. Run digester agent
    // 3. Clear from Redis
  }
}
```

#### 3.2 Tasks
- [ ] CrÃ©er `SessionManager` class
- [ ] Modifier `MCPServer` pour utiliser SessionManager
- [ ] Extraire userId du contexte MCP (headers, env)
- [ ] ImplÃ©menter session isolation
- [ ] Ajouter `brain_session_start` / `brain_session_end` tools
- [ ] Tests multi-user concurrence

---

### Phase 4: Library Cache (Semaine 4-5)
**Objectif**: Cache Context7 pour Ã©viter re-scraping

#### 4.1 Librarian Service
```javascript
// Nouveau fichier: packages/mcp/src/services/librarian.js

class LibrarianService {
  constructor(persistence, context7Client) {
    this.persistence = persistence;
    this.context7 = context7Client;
  }

  async getDocumentation(libraryId, query) {
    // 1. Check PostgreSQL cache (library_cache table)
    // 2. If cache hit + not expired â†’ return cached
    // 3. If miss â†’ fetch from Context7
    // 4. Store in cache with appropriate TTL
    // 5. Return content
  }

  async preloadEcosystemDocs() {
    // Pre-fetch and cache:
    // - @solana/web3.js
    // - helius-sdk
    // - ioredis
    // - express
    // - All CLAUDE.md files
  }
}
```

#### 4.2 Tasks
- [ ] CrÃ©er `LibrarianService`
- [ ] ImplÃ©menter cache lookup + TTL
- [ ] ImplÃ©menter pre-fetch pour libs essentielles
- [ ] Ajouter `brain_docs` tool (wrapper autour de context7)
- [ ] CrÃ©er cron job pour refresh cache
- [ ] Dashboard cache stats

---

### Phase 5: Specialized Sub-Agents (Semaine 5-6)
**Objectif**: Agents experts pour domaines spÃ©cifiques

#### 5.1 Agent Definitions
```bash
# Fichiers Ã  crÃ©er
asdf-brain/.claude/agents/
â”œâ”€â”€ cynic-observer.md         # Existe dÃ©jÃ 
â”œâ”€â”€ cynic-digester.md         # Existe dÃ©jÃ 
â”œâ”€â”€ cynic-guardian.md         # Existe dÃ©jÃ 
â”œâ”€â”€ cynic-mentor.md           # Existe dÃ©jÃ 
â”œâ”€â”€ cynic-librarian.md        # NOUVEAU - Cache docs
â”œâ”€â”€ cynic-holdex-expert.md    # NOUVEAU - K-Score expert
â”œâ”€â”€ cynic-gasdf-expert.md     # NOUVEAU - Gasless expert
â”œâ”€â”€ cynic-solana-expert.md    # NOUVEAU - Web3 expert
â”œâ”€â”€ cynic-architect.md        # NOUVEAU - Design review
â””â”€â”€ cynic-integrator.md       # NOUVEAU - Cross-project sync
```

#### 5.2 Tasks
- [ ] CrÃ©er agent `cynic-librarian` (cache + fetch docs)
- [ ] CrÃ©er agent `cynic-holdex-expert` (K-Score, E-Score)
- [ ] CrÃ©er agent `cynic-gasdf-expert` (burns, fees)
- [ ] CrÃ©er agent `cynic-solana-expert` (web3.js, SPL)
- [ ] CrÃ©er agent `cynic-architect` (design review + judge)
- [ ] CrÃ©er agent `cynic-integrator` (cross-project sync)
- [ ] DÃ©finir triggers et contextes
- [ ] Tests isolation agents

---

### Phase 6: Knowledge Pre-loading (Semaine 6-7)
**Objectif**: CYNIC connaÃ®t l'Ã©cosystÃ¨me au dÃ©marrage

#### 6.1 Pre-load Script
```javascript
// Script: packages/persistence/scripts/preload-ecosystem.js

async function preloadEcosystem() {
  const docs = [
    // Core shared modules
    { project: 'holdex', type: 'harmony', path: 'HolDex/src/shared/harmony.js' },
    { project: 'holdex', type: 'claude_md', path: 'HolDex/CLAUDE.md' },
    { project: 'gasdf', type: 'claude_md', path: 'GASdf/CLAUDE.md' },
    { project: 'brain', type: 'claude_md', path: 'asdf-brain/CLAUDE.md' },
    { project: 'ecosystem', type: 'claude_md', path: 'asdfasdfa-ecosystem/CLAUDE.md' },

    // API docs
    { project: 'holdex', type: 'api', path: 'HolDex/docs/API.md' },
    { project: 'holdex', type: 'kscore', path: 'HolDex/docs/KSCORE.md' },
  ];

  for (const doc of docs) {
    const content = await fs.readFile(doc.path, 'utf-8');
    const digest = await cynic.digest(content);
    await persistence.ecosystemDocs.upsert(doc.project, doc.type, content, digest);
  }
}
```

#### 6.2 Tasks
- [ ] CrÃ©er script de pre-load
- [ ] Identifier tous les docs critiques
- [ ] GÃ©nÃ©rer digests AI pour chaque doc
- [ ] Stocker dans `ecosystem_docs` table
- [ ] Ajouter Ã  startup MCP server
- [ ] Refresh automatique si fichiers changent

---

### Phase 7: PoJ Chain Persistence (Semaine 7-8)
**Objectif**: Blockchain de jugements persistante

#### 7.1 PoJ Repository
```javascript
// packages/persistence/src/postgres/repositories/poj-chain.js

class PoJChainRepository {
  async getHead() { /* Return latest block */ }
  async getBlock(blockNumber) { /* Return specific block */ }
  async addBlock(block) { /* Append new block */ }
  async verifyChain() { /* Verify SHA-256 links */ }
  async exportChain() { /* Export full chain */ }
  async importChain(blocks) { /* Import chain (migration) */ }
}
```

#### 7.2 Tasks
- [ ] ImplÃ©menter `PoJChainRepository`
- [ ] Modifier `brain_cynic_judge` pour crÃ©er blocks
- [ ] Batch judgments en blocks (toutes les N judgments ou T secondes)
- [ ] VÃ©rification cryptographique au startup
- [ ] Export/import pour backup
- [ ] Dashboard chain explorer

---

### Phase 8: Cross-Project Integration (Semaine 8-9)
**Objectif**: CYNIC orchestre l'Ã©cosystÃ¨me

#### 8.1 Integrator Service
```javascript
// packages/mcp/src/services/integrator.js

class IntegratorService {
  // Modules partagÃ©s qui doivent rester sync
  SHARED_MODULES = [
    { name: 'harmony.js', projects: ['holdex', 'gasdf'] },
    { name: 'PHI constants', files: ['*/constants.js', '*/phi.js'] },
  ];

  async checkSync() {
    // Compare file hashes across projects
    // Return diff report
  }

  async suggestSync(change) {
    // Given a change in one project
    // Suggest changes needed in others
  }
}
```

#### 8.2 Tasks
- [ ] CrÃ©er `IntegratorService`
- [ ] DÃ©finir modules partagÃ©s
- [ ] ImplÃ©menter dÃ©tection de drift
- [ ] Hook sur git commits
- [ ] Alertes si dÃ©sync dÃ©tectÃ©

---

### Phase 9: Monitoring & Dashboard (Semaine 9-10)
**Objectif**: VisibilitÃ© sur la conscience CYNIC

#### 9.1 MÃ©triques
```javascript
// MÃ©triques Ã  exposer (Prometheus format)
cynic_judgments_total{verdict="WAG"} 42
cynic_judgments_total{verdict="HOWL"} 5
cynic_avg_q_score 51.7
cynic_active_sessions 3
cynic_library_cache_hits 156
cynic_library_cache_misses 12
cynic_patterns_total{status="approved"} 23
cynic_users_total 2
cynic_poj_chain_height 100
```

#### 9.2 Tasks
- [ ] CrÃ©er endpoint `/metrics` sur MCP server
- [ ] Exposer stats judgments, sessions, cache
- [ ] CrÃ©er dashboard Grafana (ou simple HTML)
- [ ] Alertes si Q-Score moyen chute
- [ ] Alertes si chain invalide

---

## ğŸ“… TIMELINE VISUELLE

```
Semaine 1-2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Phase 1: Persistence Layer
Semaine 2-3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ Phase 2: MCP Integration
Semaine 3-4: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 3: Multi-User Sessions
Semaine 4-5: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 4: Library Cache
Semaine 5-6: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 5: Sub-Agents
Semaine 6-7: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 6: Knowledge Pre-load
Semaine 7-8: â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 7: PoJ Chain
Semaine 8-9: â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 8: Cross-Project
Semaine 9-10: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Phase 9: Monitoring
```

---

## ğŸ¯ CRITÃˆRES DE SUCCÃˆS

### Phase 1 Complete When:
- [ ] `brain_search("harmony")` retourne des rÃ©sultats aprÃ¨s restart
- [ ] Judgments persistent entre sessions
- [ ] Tests passent avec vraie DB Render

### Phase 2 Complete When:
- [ ] Tous les MCP tools utilisent PostgreSQL
- [ ] brain_search supporte full-text search
- [ ] Performance < 100ms pour search

### Phase 3 Complete When:
- [ ] 2 users concurrent ne voient pas les donnÃ©es de l'autre
- [ ] Session isolation vÃ©rifiÃ© par tests
- [ ] E-Score calculÃ© par user

### Phase 4 Complete When:
- [ ] Context7 calls rÃ©duits de 80%
- [ ] Cache hit rate > 70%
- [ ] Pre-load fonctionne au startup

### Phase 5 Complete When:
- [ ] Librarian fetch + cache docs automatiquement
- [ ] HolDex expert rÃ©pond questions K-Score
- [ ] Architect judge les designs

### Full Success When:
- [ ] CYNIC survit aux restarts sans perte de mÃ©moire
- [ ] Multi-user isolation complÃ¨te
- [ ] Ecosystem docs toujours Ã  jour
- [ ] Q-Score moyen stable > 50
- [ ] 0 re-fetch inutile de docs

---

## ğŸ“š RÃ‰FÃ‰RENCES

### Fichiers ClÃ©s Ã  Lire
```
CYNIC-new/packages/mcp/src/server.js          # MCP Server actuel
CYNIC-new/packages/node/src/judge/judge.js    # CYNICJudge
CYNIC-new/packages/node/src/state/manager.js  # StateManager actuel
HolDex/src/shared/harmony.js                  # Ï† formulas
HolDex/CLAUDE.md                              # HolDex context
GASdf/CLAUDE.md                               # GASdf context
asdf-brain/CLAUDE.md                          # Brain context
```

### Connexions Production
```bash
# cynic-db PostgreSQL
Host: oregon-postgres.render.com
Database: cynic_db
User: cynic_db_user

# Redis (Ã  crÃ©er si besoin, ou utiliser existant)
# Option 1: CrÃ©er cynic-redis
# Option 2: Utiliser holdex-redis avec namespace
```

---

## ğŸ• PHILOSOPHIE CYNIC

> "Don't trust, verify. Don't extract, burn."

```
Ï†â»Â¹ = 61.8% â†’ Max confidence (never 100%)
Ï†â»Â² = 38.2% â†’ Min doubt (always question)

Q-Score = 100 Ã— âˆœ(PHI Ã— VERIFY Ã— CULTURE Ã— BURN)

HOWL (â‰¥80) â†’ *howls approvingly*
WAG  (â‰¥50) â†’ *wags steadily*
GROWL(â‰¥38) â†’ *low growl*
BARK (<38) â†’ *barks warning*
```

---

*Document maintenu par CYNIC | Ï† Confidence: 61.8% | Last updated: 2026-01-15*
